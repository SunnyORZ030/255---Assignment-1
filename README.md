# CMPE 255 â€” Assignment 1: Do Data Science with ChatGPT

> Semester: Fall 2025   
> Date: 2025-09-13

## ğŸ¯ Objective
Use **ChatGPT as a copilot** to complete an end-to-end data science workflow on a dataset from **Kaggle**.

## âœ… Dataset Chosen (Newbie-friendly)
- **Dataset**: *Titanic â€” Machine Learning from Disaster* (Kaggle)  
- **Target (ç›®æ¨™æ¬„ä½)**: `Survived`ï¼ˆ0=æœªå­˜æ´», 1=å­˜æ´»ï¼‰  
- **Task**: Binary Classification  
- **Suggested features**: Drop identifiers like `PassengerId`, `Name`, `Ticket`, `Cabin` for the baseline.

## ğŸ“ Repo Layout
```
assignment-1/
  â”œâ”€ README.md
  â”œâ”€ prompts.md
  â”œâ”€ transcript.md
  â”œâ”€ requirements.txt
  â”œâ”€ .gitignore
  â”œâ”€ data/
  â”œâ”€ notebooks/
  â”‚   â”œâ”€ assignment1.ipynb             â† generic
  â”‚   â””â”€ assignment1_titanic.ipynb     â† prefilled with target & steps
  â”œâ”€ src/
  â”‚   â””â”€ utils.py
  â”œâ”€ artifacts/
  â””â”€ results/
```

## ğŸ› ï¸ Steps (High-level)
1. Data Understanding â†’ 2. Data Preparation â†’ 3. Modeling â†’ 4. Evaluation â†’ 5. Iteration â†’ 6. Report & Artifacts

## â–¶ï¸ How to run (Colab)
- Open `notebooks/assignment1_titanic.ipynb` in **Google Colab**.
- Option A: Upload `train.csv` manuallyï¼›Option B: use Kaggle API to download the Titanic dataset.
- Run cells top-to-bottom; artifacts/metrics will be saved into `artifacts/` and `results/`.

## ğŸ§ª Reproducibility
- Python: 3.10+
- Install deps: `pip install -r requirements.txt`
- Use a fixed `random_state` for splits.

## ğŸ“ˆ Fill after you run
- Best Model: â€¦  
- Metrics: Accuracy=â€¦, F1(macro)=â€¦, ROC-AUC=â€¦  
- Takeaways: â€¦  

## âœ… Submission Checklist
- [ ] Public GitHub repo
- [ ] README updated with results
- [ ] Transcript in `transcript.md`
- [ ] Notebook runs end-to-end
- [ ] Artifacts saved to `artifacts/` or `results/`
