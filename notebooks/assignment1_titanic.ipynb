{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Assignment 1 — Titanic (Binary Classification)\n",
        "\n",
        "**Dataset**: Kaggle *Titanic — Machine Learning from Disaster*\n",
        "**Target**: `Survived` (0=not survived, 1=survived)\n",
        "**Goal Metrics**: Accuracy, F1(macro), ROC-AUC\n",
        "\n",
        "Tips:\n",
        "- For the baseline, drop obvious identifier columns such as `PassengerId`, `Name`, `Ticket`, `Cabin`.\n",
        "- Keep the workflow simple and reproducible; set a fixed `random_state`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "RANDOM_STATE = 42\n",
        "ARTIFACTS = Path('../artifacts'); ARTIFACTS.mkdir(parents=True, exist_ok=True)\n",
        "RESULTS = Path('../results'); RESULTS.mkdir(parents=True, exist_ok=True)\n",
        "print('Setup complete')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Load Data\n",
        "**Option A (manual upload)**: In Colab → `Files` panel → Upload `train.csv`.\n",
        "\n",
        "**Option B (Kaggle API)**:\n",
        "```\n",
        "!pip install kaggle -q\n",
        "from google.colab import files; files.upload()   # upload kaggle.json (do not commit it)\n",
        "!mkdir -p ~/.kaggle && cp kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c titanic -p /content\n",
        "!unzip -o /content/titanic.zip -d /content\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If you uploaded `train.csv` to /content\n",
        "df = pd.read_csv('/content/train.csv')  # adjust path if needed\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Basic EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df.shape)\n",
        "print(df.dtypes)\n",
        "print(df.isna().sum().sort_values(ascending=False).head(10))\n",
        "df['Survived'].value_counts(normalize=True).plot(kind='bar', title='Target Balance'); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Train/Dev/Test Split (with simple cleaning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TARGET = 'Survived'\n",
        "X = df.drop(columns=[TARGET, 'PassengerId','Name','Ticket','Cabin'])\n",
        "y = df[TARGET]\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
        ")\n",
        "X_dev, X_test, y_dev, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=RANDOM_STATE, stratify=y_temp\n",
        ")\n",
        "X_train.shape, X_dev.shape, X_test.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Preprocessing (ColumnTransformer) + Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "num_cols = X_train.select_dtypes(include=['int64','float64']).columns\n",
        "cat_cols = X_train.select_dtypes(include=['object','category','bool']).columns\n",
        "\n",
        "numeric_transformer = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler(with_mean=False))\n",
        "])\n",
        "categorical_transformer = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocess = ColumnTransformer([\n",
        "    ('num', numeric_transformer, num_cols),\n",
        "    ('cat', categorical_transformer, cat_cols)\n",
        "])\n",
        "\n",
        "log_reg = Pipeline([('prep', preprocess), ('model', LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))])\n",
        "rf_clf  = Pipeline([('prep', preprocess), ('model', RandomForestClassifier(n_estimators=400, random_state=RANDOM_STATE))])\n",
        "log_reg, rf_clf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Evaluate on Dev Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, ConfusionMatrixDisplay, RocCurveDisplay\n",
        "\n",
        "models = {'log_reg': log_reg, 'rf': rf_clf}\n",
        "scores = {}\n",
        "for name, mdl in models.items():\n",
        "    mdl.fit(X_train, y_train)\n",
        "    dev_pred = mdl.predict(X_dev)\n",
        "    dev_proba = mdl.predict_proba(X_dev)[:,1] if hasattr(mdl, 'predict_proba') else None\n",
        "    acc = accuracy_score(y_dev, dev_pred)\n",
        "    f1m = f1_score(y_dev, dev_pred, average='macro')\n",
        "    roc = roc_auc_score(y_dev, dev_proba) if dev_proba is not None else float('nan')\n",
        "    scores[name] = {'accuracy':acc, 'f1_macro':f1m, 'roc_auc':roc}\n",
        "    print(name, scores[name])\n",
        "\n",
        "# choose best by F1(macro)\n",
        "best_name = max(scores, key=lambda k: scores[k]['f1_macro'])\n",
        "best_model = models[best_name]\n",
        "print('Best model (dev):', best_name, scores[best_name])\n",
        "\n",
        "# Confusion matrix on dev\n",
        "ConfusionMatrixDisplay.from_estimator(best_model, X_dev, y_dev)\n",
        "plt.title(f'Confusion Matrix (dev) — {best_name}')\n",
        "plt.tight_layout(); plt.savefig(ARTIFACTS/'confusion_matrix_dev.png'); plt.show()\n",
        "\n",
        "if hasattr(best_model, 'predict_proba'):\n",
        "    RocCurveDisplay.from_estimator(best_model, X_dev, y_dev)\n",
        "    plt.title(f'ROC Curve (dev) — {best_name}')\n",
        "    plt.tight_layout(); plt.savefig(ARTIFACTS/'roc_curve_dev.png'); plt.show()\n",
        "\n",
        "import pandas as pd\n",
        "pd.DataFrame(scores).T.to_csv(RESULTS/'dev_scores.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Retrain on Train+Dev and Evaluate on Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_trd = pd.concat([X_train, X_dev], axis=0)\n",
        "y_trd = pd.concat([y_train, y_dev], axis=0)\n",
        "best_model.fit(X_trd, y_trd)\n",
        "test_pred = best_model.predict(X_test)\n",
        "test_proba = best_model.predict_proba(X_test)[:,1] if hasattr(best_model, 'predict_proba') else None\n",
        "acc = accuracy_score(y_test, test_pred)\n",
        "f1m = f1_score(y_test, test_pred, average='macro')\n",
        "roc = roc_auc_score(y_test, test_proba) if test_proba is not None else float('nan')\n",
        "summary = {'best_model': best_name, 'test_accuracy': acc, 'test_f1_macro': f1m, 'test_roc_auc': roc}\n",
        "print(summary)\n",
        "pd.DataFrame([summary]).to_csv(RESULTS/'test_summary.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Wrap-up Notes for README"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Suggested README bullets:')\n",
        "print('- Problem: Predict survival on Titanic using tabular features')\n",
        "print('- Method: Simple preprocessing + baseline Logistic Regression vs RandomForest')\n",
        "print('- Best model (dev):', best_name, '→ see results/dev_scores.csv')\n",
        "print('- Final test metrics: see results/test_summary.csv')\n",
        "print('- Artifacts saved in artifacts/ (confusion matrix, ROC)')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}